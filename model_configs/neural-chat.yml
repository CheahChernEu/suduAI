model_type: ollama
model: neural-chat:7b-v3.2-q5_K_M
context_length: 2048
max_tokens: 2048
temperature: 0.0
stop: []
last_n_tokens: 2048
prompt_template: "### System:
{system_message}

### User:
{prompt}

### Assistant:"

prefix_template: "### System:
{prefix_text}

"

suffix_template: "### User:
{suffix_text}

### Assistant:"